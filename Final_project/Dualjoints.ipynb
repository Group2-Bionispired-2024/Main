{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c5863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import camera_tools as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a784c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmac2 import CMAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74871f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calibrate the camera to detect green box, if you haven't done this calibration before\n",
    "low_green, high_green = ct.colorpicker()\n",
    "print(low_green)\n",
    "print(high_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e572fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_red, high_red = ct.colorpicker()\n",
    "print(low_red)\n",
    "print(high_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0e3103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check whether the camera detects the green object properly\n",
    "cam = ct.prepare_camera()\n",
    "image = ct.capture_image(cam)\n",
    "x,y = ct.locate(image, low_green, high_green)\n",
    "ct.show_camera(cam)\n",
    "\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c6b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check whether the camera detects the green object properly\n",
    "cam_red = ct.prepare_camera()\n",
    "img_red = ct.capture_image(cam_red)\n",
    "ct.show_camera(cam_red, low_red, high_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e258dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FableAPI.fable_init import api\n",
    "api.setup(blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70b71f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "moduleids = api.discoverModules()\n",
    "print(\"Module IDs: \", moduleids)\n",
    "moduleID = moduleids[0]\n",
    "print(\"Battery level:\",api.getBattery(moduleID),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b361e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two files (if they were not already created) to collect data.\n",
    "if (not os.path.exists(\"xycoords_2.csv\")):\n",
    "    f = open('xycoords_2.csv', 'w')\n",
    "    with f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[\"X\",\"Y\"]])\n",
    "    f.close()\n",
    "if (not os.path.exists(\"angles_2.csv\")):\n",
    "    f = open('angles_2.csv','w')\n",
    "    with f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[\"Y_angle\"]])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f2825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t1 = 20\n",
    "n_t2 = 20\n",
    "\n",
    "t1 = np.tile(np.linspace(-85, 86, n_t1), n_t2) # repeat the vector\n",
    "t2 = np.repeat(np.linspace(0, 86, n_t2), n_t1) # repeat each element\n",
    "thetas = np.stack((t1,t2))\n",
    "\n",
    "num_datapoints = n_t1*n_t2\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.scatter(thetas[0], thetas[1])\n",
    "# plt.xlabel('t1')\n",
    "# plt.ylabel('t2')\n",
    "# plt.title('Grid of Points')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72500dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ourdata = np.zeros((4, num_datapoints))\n",
    "\n",
    "def collect_data_2D(num_datapoints):\n",
    "    for i in range(num_datapoints):\n",
    "        api.setPos(thetas[0,i], thetas[1,i], moduleID)\n",
    "        img = ct.capture_image(cam)\n",
    "        x, y = ct.locate(img, low_green, high_green)\n",
    "        tmeas1 = api.getPos(0,moduleID)\n",
    "        tmeas2 = api.getPos(1,moduleID)\n",
    "        ourdata = np.array([tmeas1, tmeas2, x, y])\n",
    "        with open('xycoords_2.csv', 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows([ourdata[2:4]])\n",
    "        with open('angles_2.csv', 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows([ourdata[0:2]])\n",
    "        api.sleep(2)\n",
    "    return None\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd0af44",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_data_2D(num_datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b78dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use the collectData function to collect the data for training.\n",
    "    #we collect Y (angular) position of the end effector\n",
    "    #we collect x,y coordinates of the end effector in the camera image\n",
    "    #see the video final_project_guidance.mp4\n",
    "def collectData(desired_angle_change):\n",
    "    cam = ct.prepare_camera()\n",
    "    ct.show_camera(cam)\n",
    "    cam.release()\n",
    "    cam = ct.prepare_camera()\n",
    "    api.setPos(-90,90,moduleID)\n",
    "    api.sleep(1.5)\n",
    "    Y_angle_list = []\n",
    "    XY_coordinates_list = []\n",
    "    traversed_directions = 0\n",
    "    current_direction = 0     # 1 is for clockwise, 0 is for anticlockwise\n",
    "    traversedDirections = 0\n",
    "    num_of_iterations = (int)(np.round(360/desired_angle_change,1))\n",
    "    #Fable's Y arm traverse anticlockwise\n",
    "    if current_direction == 0:\n",
    "        for i in range(num_of_iterations):\n",
    "            img = ct.capture_image(cam)\n",
    "            x,y = ct.locate(img, low_green, high_green)\n",
    "            currentRobotYAng = (int)(np.round(api.getPos(1,moduleID),1))\n",
    "            Y_angle_list.append([currentRobotYAng])\n",
    "            XY_coordinates_list.append([x,y])\n",
    "            currentRobotYAng = currentRobotYAng - (desired_angle_change)\n",
    "            api.setPos(-90,currentRobotYAng,moduleID)\n",
    "            api.sleep(1.5)\n",
    "            if np.abs(currentRobotYAng) > 90:\n",
    "                current_direction = 1\n",
    "                traversedDirections = traversedDirections + 1\n",
    "                break\n",
    "    #Fable's Y Arm traverses clockwise\n",
    "    if current_direction == 1:\n",
    "        for i in range(num_of_iterations):\n",
    "            img = ct.capture_image(cam)\n",
    "            x,y = ct.locate(img, low_green, high_green)\n",
    "            currentRobotYAng = (int)(np.round(api.getPos(1,moduleID),1))\n",
    "            Y_angle_list.append([currentRobotYAng])\n",
    "            XY_coordinates_list.append([x,y])\n",
    "            currentRobotYAng = currentRobotYAng + (desired_angle_change)\n",
    "            api.setPos(-90,currentRobotYAng,moduleID)\n",
    "            api.sleep(1.5)\n",
    "            if np.abs(currentRobotYAng) > 90:\n",
    "                current_direction = 0\n",
    "                traversedDirections = traversedDirections + 1\n",
    "                break\n",
    "    if traversedDirections == 2:\n",
    "        cam.release()\n",
    "        #Save collected data to files\n",
    "        y_angle_file_ptr = open('angles_2.csv', 'a+', newline ='')\n",
    "        with y_angle_file_ptr:\n",
    "            writer = csv.writer(y_angle_file_ptr)\n",
    "            writer.writerows(Y_angle_list)\n",
    "        y_angle_file_ptr.close()\n",
    "        file_xycoords = open('xycoords_2.csv', 'a+', newline ='')\n",
    "        with file_xycoords:\n",
    "            writer = csv.writer(file_xycoords)\n",
    "            writer.writerows(XY_coordinates_list)\n",
    "        file_xycoords.close()\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14beede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Call the CollectData() function with different values for 'desired_angle_change' argument and collect sufficient\n",
    "#sufficient amout of data to angles_2.csv file and xycoords_2.csv file.\n",
    "collectData(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845578e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this function to calculate Y (angular) position errors \n",
    "# Y (angular) positions\n",
    "def readAngleFilesAndCollectErrors(fileName):\n",
    "    angleDataFrame = pd.read_csv(fileName)\n",
    "    desired1_column = angleDataFrame.columns[0]\n",
    "    desired2_column = angleDataFrame.columns[1]\n",
    "    angle1_error_list = []\n",
    "    angle2_error_list = []\n",
    "    for i in range(1,len(angleDataFrame)):\n",
    "        current1_data_element = angleDataFrame[desired1_column][i]\n",
    "        previous1_data_element = angleDataFrame[desired1_column][i-1]\n",
    "        current2_data_element = angleDataFrame[desired2_column][i]\n",
    "        previous2_data_element = angleDataFrame[desired2_column][i-1]\n",
    "\n",
    "        #TODO: Calculate the Y (angular) position error(say current_error) as the difference between \n",
    "        # the current Y (angular) position and previous Y (angular) position\n",
    "\n",
    "        current_error1 = current1_data_element - previous1_data_element\n",
    "        current_error2 = current2_data_element - previous2_data_element\n",
    "\n",
    "        #print(current_data_element,\" \", previous_data_element, \" \", current_error)\n",
    "        angle1_error_list = angle1_error_list + [current_error1]\n",
    "        angle2_error_list = angle2_error_list + [current_error2]\n",
    "\n",
    "    return [angle1_error_list, angle2_error_list] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aed3f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this function to calculate errors between x and y coordinates\n",
    "def readXYCoordsFilesAndCollectErrors(fileName):\n",
    "    xyCoordsDataFrame = pd.read_csv(fileName)\n",
    "    x_col_name = xyCoordsDataFrame.columns[0]\n",
    "    y_col_name = xyCoordsDataFrame.columns[1]\n",
    "    x_pos_error_list = []\n",
    "    y_pos_error_list = []\n",
    "    for i in range(1,len(xyCoordsDataFrame)):\n",
    "        current_data_element_x = xyCoordsDataFrame[x_col_name][i]\n",
    "        current_data_element_y = xyCoordsDataFrame[y_col_name][i]\n",
    "        previous_data_element_x = xyCoordsDataFrame[x_col_name][i-1]\n",
    "        previous_data_element_y = xyCoordsDataFrame[y_col_name][i-1]\n",
    "        error_x_pos = current_data_element_x - previous_data_element_x \n",
    "        error_y_pos = current_data_element_y - previous_data_element_y\n",
    "        x_pos_error_list = x_pos_error_list + [error_x_pos]\n",
    "        y_pos_error_list = y_pos_error_list + [error_y_pos] \n",
    "    return [x_pos_error_list,y_pos_error_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d283c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the provided files and load the calculated errors into to appropriate lists as follows\n",
    "# angle_error_list_1 = readAngleFilesAndCollectErrors(\"angles_1.csv\")\n",
    "# x_pos_error_list_1,y_pos_error_list_1 = readXYCoordsFilesAndCollectErrors(\"xyCoords_1.csv\")\n",
    "#Read the files with the data dumped by you and load the calculated errors into appropriate lists.\n",
    "angle1_error_list_2, angle2_error_list_2 = readAngleFilesAndCollectErrors(\"angles_2.csv\")\n",
    "x_pos_error_list_2,y_pos_error_list_2 = readXYCoordsFilesAndCollectErrors(\"xyCoords_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0ba5fe",
   "metadata": {},
   "source": [
    "Remove first entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514cd8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle1_error_list_2 = angle1_error_list_2[1:]\n",
    "angle2_error_list_2 = angle2_error_list_2[1:]\n",
    "x_pos_error_list_2 = x_pos_error_list_2[1:]\n",
    "y_pos_error_list_2 = y_pos_error_list_2[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3f378a",
   "metadata": {},
   "source": [
    "Standardize errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2854df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_x_pos_1 = np.mean(x_pos_error_list_1)\n",
    "# mean_y_pos_1 = np.mean(y_pos_error_list_1)\n",
    "# std_x_pos_1 = np.std(x_pos_error_list_1)\n",
    "# std_y_pos_1 = np.std(y_pos_error_list_1)\n",
    "# x_pos_error_list_2 = np.array(x_pos_error_list_2[1:])\n",
    "# mean_x_pos_2 = np.mean(x_pos_error_list_2)\n",
    "# mean_y_pos_2 = np.mean(y_pos_error_list_2)\n",
    "# std_x_pos_2 = np.std(x_pos_error_list_2)\n",
    "# std_y_pos_2 = np.std(y_pos_error_list_2)\n",
    "# print(mean_x_pos_2,mean_y_pos_2,std_x_pos_2,std_y_pos_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1426d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# angle_error_list_1 = (angle_error_list_1 - np.mean(angle_error_list_1))/np.std(angle_error_list_1)\n",
    "# x_pos_error_list_1 = (x_pos_error_list_1 - np.mean(x_pos_error_list_1,0))/np.std(x_pos_error_list_1,0)\n",
    "# y_pos_error_list_1 = (y_pos_error_list_1 - np.mean(y_pos_error_list_1,0))/np.std(y_pos_error_list_1,0)\n",
    "# # print(\"Angle error list 1: \",angle_error_list_1.shape)\n",
    "# print(\"X position error list 1: \",x_pos_error_list_1.shape)\n",
    "# print(\"Y position error list 1: \",y_pos_error_list_1.shape)\n",
    "# angle_error_list_2 = (angle_error_list_2 - np.mean(angle_error_list_2))/np.std(angle_error_list_2)\n",
    "#--------------------------------------\n",
    "# x_pos_error_list_2 = (x_pos_error_list_2 - np.mean(x_pos_error_list_2))/np.std(x_pos_error_list_2)\n",
    "# y_pos_error_list_2 = (y_pos_error_list_2 - np.mean(y_pos_error_list_2))/np.std(y_pos_error_list_2)\n",
    "# print(x_pos_error_list_2)\n",
    "# # print(\"Angle error list 2: \",angle_error_list_2.shape)\n",
    "# print(\"X position error list 2: \",x_pos_error_list_2.shape)\n",
    "# print(\"Y position error list 2: \",y_pos_error_list_2.shape)\n",
    "x_coord_error_array = np.array(x_pos_error_list_2)\n",
    "y_coord_error_array = np.array(y_pos_error_list_2)\n",
    "angle1_error_array = np.array(angle1_error_list_2)\n",
    "angle2_error_array = np.array(angle2_error_list_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fe5887",
   "metadata": {},
   "source": [
    "Merge them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d048e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # angle_error_array = np.concatenate((angle_error_list_1,angle_error_list_2),axis=0)\n",
    "# x_coord_error_array = np.concatenate((x_pos_error_list_1,x_pos_error_list_2),axis=0)\n",
    "# y_coord_error_array = np.concatenate((y_pos_error_list_1,y_pos_error_list_2),axis=0)\n",
    "# print(\"Angle error array: \",angle_error_array.shape)\n",
    "# print(\"X position error array: \",x_coord_error_array.shape)\n",
    "# print(\"Y position error array: \",y_coord_error_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfb6b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #merge both angle_error_list_1 and angle_error_list_2 to a single list and make it a numpy array called 'angle_error_array'\n",
    "# # angle_error_array = np.array(angle_error_list_1 + angle_error_list_2 )\n",
    "# angle_error_array = angle_error_list_2\n",
    "# #merge both x_pos_error_list_1 and x_pos_error_list_2 to a single list and make it a numpy array called 'x_coord_error_array'\n",
    "# # x_coord_error_array = np.array(x_pos_error_list_1 + x_pos_error_list_2)\n",
    "# x_coord_error_array = x_pos_error_list_2\n",
    "# #merge both y_pos_error_list_1 and y_pos_error_list_2 to a single list and make it a numpy array called 'y_coord_error_array'\n",
    "# # y_coord_error_array = np.array(y_pos_error_list_1 + y_pos_error_list_2)\n",
    "# y_coord_error_array = y_pos_error_list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fc81dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.array([angle_error_array,x_coord_error_array,y_coord_error_array])\n",
    "# target = np.array([angle_error_array,x_coord_error_array,y_coord_error_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a24914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use 80% of the collected data  as the training set and 20% of the collected data as test set.\n",
    "#TODO: Assign different propotions of the collected data set and test set and check how the test set error varies of the \n",
    "#Neural Network\n",
    "data =  np.vstack((x_coord_error_array,y_coord_error_array)).T\n",
    "target = np.vstack(angle_error_array)\n",
    "# print(data)\n",
    "# print(target)\n",
    "data_input_tensor = torch.tensor(data.tolist()).float()\n",
    "data_target_tensor = torch.tensor(target.tolist()).float()\n",
    "data_with_target = torch.cat((data_input_tensor,data_target_tensor),1)\n",
    "#TODO: what is the importance of using DataLoader utility function here?\n",
    "loader= torch.utils.data.DataLoader(data_with_target,\n",
    "                                     batch_size=data_with_target.size()[0], shuffle=True,\n",
    "                                     num_workers=0)\n",
    "#training set\n",
    "train_set = []\n",
    "#test set\n",
    "test_set = []\n",
    "for i in iter(loader):\n",
    "    train_set_index = (int)(np.round(i.shape[0]*0.8))\n",
    "    train_set = i[:train_set_index,:]\n",
    "    test_set = i[train_set_index:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5578004",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70582f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Neural Network Model\n",
    "class NN(torch.nn.Module):\n",
    "    def __init__(self,n_feature,n_hidden1,n_hidden2,n_output):\n",
    "        super(NN,self).__init__()\n",
    "        self.hidden1 = torch.nn.Linear(n_feature,n_hidden1)\n",
    "        #self.do1 = torch.nn.Dropout(0.15)\n",
    "        #self.relu1 = torch.nn.LeakyReLU()\n",
    "        #self.bn1 = torch.nn.BatchNorm1d(n_hidden1,affine=False)\n",
    "        self.hidden2 = torch.nn.Linear(n_hidden1,n_hidden2)\n",
    "        #self.bn2 = torch.nn.BatchNorm1d(n_hidden2,affine=False)\n",
    "        #self.relu2 = torch.nn.LeakyReLU()\n",
    "        #self.do2 = torch.nn.Dropout(0.1)\n",
    "        self.predict = torch.nn.Linear(n_hidden2,n_output)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.hidden1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        #x = self.do1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        #x = self.do2(x)\n",
    "        x = self.predict(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f4f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the Neural Network\n",
    "#model = NN(n_feature=2,n_hidden1=17,n_hidden2=7, n_output=1)\n",
    "model = NN(n_feature=2,n_hidden1=100,n_hidden2=100, n_output=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3a93a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define loss function : \n",
    "# here we use Mean Square Error as the loss function\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb61a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the optimizer that should be used in training the Neural Network.\n",
    "# Here 'lr' is the learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8563f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_inputs = train_set[:,:2]\n",
    "#TODO: calculate the mean value of the train_set_inputs. \n",
    "mean_of_train_input = torch.mean(train_set_inputs,0)\n",
    "#standard deviation of the train set inputs.\n",
    "std_of_the_train_input = torch.std(train_set_inputs,0)\n",
    "#here we normalize the inputs of the neural network. What is the importance of that?\n",
    "normalized_train_set_inputs = (train_set_inputs - mean_of_train_input)/std_of_the_train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e10aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#targets of the training set\n",
    "train_set_targets = train_set[:,2][:,np.newaxis]\n",
    "# train_set_inputs = train_set[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b66a79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normalized_train_set_inputs.shape)\n",
    "print(train_set_targets.shape)\n",
    "# print(train_set_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceb0ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: train the Neural network model by changing the hyper parameters such as learning rate, number of epochs, number of neurons in hidden layers of the neural network.\n",
    "# What is the minimum mean square error that you can achieve as your neural network converges for the training set.\n",
    "#  (you will be able to achive a MSE of less than 10 as the Neural network converges.)\n",
    "num_epochs = 10000\n",
    "losslist = []\n",
    "for _ in range(num_epochs):\n",
    "    prediction = model(normalized_train_set_inputs) # Forward pass prediction. Saves intermediary values required for backwards pass\n",
    "    loss = loss_func(prediction, train_set_targets) # Computes the loss for each example, using the loss function defined above\n",
    "    optimizer.zero_grad() # Clears gradients from previous iteration\n",
    "    loss.backward() # Backpropagation of errors through the network\n",
    "    optimizer.step() # Updating weights\n",
    "    # print(\"prediction =\",prediction)\n",
    "    # print(\"Loss: \", loss.detach().numpy())\n",
    "    losslist.append(loss.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3192e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the mean square error in each epoch/iteration\n",
    "plt.plot(np.arange(len(losslist)),losslist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab4a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the best neural network model you have obtained.\n",
    "torch.save(model.state_dict(), 'best_nn_model.pth')\n",
    "\n",
    "#Save the mean and standard deviation of the train set inputs because we need to use them at test time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b511aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload the your best neural network model with saved parameters\n",
    "model = NN(n_feature=2,n_hidden1=100,n_hidden2=100, n_output=1)\n",
    "model.load_state_dict(torch.load('best_nn_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab535de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Extract inputs of the test_set\n",
    "test_set_inputs = test_set[:,:2]\n",
    "#TODO: Extract test set targets from the test_set\n",
    "test_set_targets = test_set[:,2][:,np.newaxis]\n",
    "print(test_set_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16007b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Normalize test set inputs by using the mean and standard deviation of the inputs of the training set\n",
    "# train_numpy = train_set_inputs.numpy()\n",
    "# mean_of_train_input = np.mean(train_numpy, axis = 0)\n",
    "# print(test_numpy)\n",
    "# print(mean_of_test_input)\n",
    "# std_of_the_train_input = np.std(train_numpy,0)\n",
    "normalized_test_set_inputs = (test_set_inputs - mean_of_train_input)/std_of_the_train_input\n",
    "print(normalized_test_set_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d504e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: feed the normalized test set inputs to the Neural Network model and obtain the prediction for the test set.\n",
    "prediction_test = model(normalized_test_set_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab886182",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84590f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the prediction error of the test set\n",
    "test_set_prediction_error = prediction_test - test_set_targets\n",
    "print(prediction_test)\n",
    "# print(test_set_prediction_error)\n",
    "plt.plot(np.arange(len(test_set_prediction_error.tolist())),test_set_prediction_error.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4334cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the example model trained with about 600 data, from a test set of 165 samples,\n",
    "# 159 samples are predicted with prediction error less than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5d782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Based on the prediction error of the test set, you can try to train the neural network again by changing the hyper parameters mentioned above.\n",
    "# Also Try to add Dropout layers to the Neural network and check whether test prediction errors can be reduced further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd3979d",
   "metadata": {},
   "source": [
    "# DETECTING THE OBJECT AT TESTING PHASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8744fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we implement the control loop which is having Neural Network as the controller.\n",
    "#In this case we donot integrate CMAC to the control loop\n",
    "def ControlLoopWithNNWithoutCMAC(target__x_coordinate,target__y_coordinate):\n",
    "    \n",
    "    number_of_iterations_for_convergence = 0\n",
    "    #TODO:Intialize your best neural network model and load the saved paramemeters\n",
    "    NN_model = NN(n_feature=2,n_hidden1=100,n_hidden2=100, n_output=1)\n",
    "    NN_model.load_state_dict(torch.load('best_nn_model.pth'))\n",
    "\n",
    "    #TODO: Obtain the x and y coodinates of the green box placed on the end effector of the robot\n",
    "    x_prev = 0\n",
    "    y_prev = 0\n",
    "    \n",
    "    #Here we loop for 50 iterations assuming that \n",
    "    # the controller should achieve the desired target within atmost 50 iterations\n",
    "    for i in range(1000):\n",
    "        cam = ct.prepare_camera()\n",
    "        img = ct.capture_image(cam)\n",
    "        x,y = ct.locate(img,low_green, high_green)\n",
    "        cam_red = ct.prepare_camera()\n",
    "        img_red = ct.capture_image(cam)\n",
    "        x_red,y_red = ct.locate(img,low_red, high_red)\n",
    "        print(x,y)\n",
    "        robot_x_coord_in_image = x\n",
    "        robot_y_coord_in_image = y\n",
    "        x_coord_error = x_red - robot_x_coord_in_image;\n",
    "        y_coord_error = y_red - robot_y_coord_in_image;\n",
    "        # print(x_coord_error,y_coord_error)\n",
    "        # x_coord_error = (x_coord_error-mean_x_pos_2)/std_x_pos_2\n",
    "        # y_coord_error = (y_coord_error-mean_y_pos_2)/std_y_pos_2\n",
    "        x_prev = x_coord_error\n",
    "        y_prev = y_coord_error\n",
    "        print(x_coord_error,y_coord_error)\n",
    "        #Here if the errors are less than twenty pixels we assume robot reaches the target. \n",
    "        # However you can choose any reasonable threshold value instead of 20.\n",
    "        # if (np.abs(x_coord_error) < (1+x_prev*1.02) and np.abs(y_coord_error) < (1+y_coord_error*1.02)):\n",
    "        #     print(\"number of iterations for convergence = \", number_of_iterations_for_convergence)\n",
    "        #     break\n",
    "        xy_input_nn_model = [x_coord_error,y_coord_error]\n",
    "        # print(xy_input_nn_model)\n",
    "        xy_input_nn_model = np.array(xy_input_nn_model)\n",
    "        #TODO: normalize the input to the Neural network model using meaning and variance of the training set inputs.\n",
    "        normalize_xy_input_nn_model = (torch.tensor(xy_input_nn_model) - mean_of_train_input)/std_of_the_train_input\n",
    "        # normalize_xy_input_nn_model = xy_input_nn_model\n",
    "        # print(normalize_xy_input_nn_model)\n",
    "        # normalize_xy_input_nn_model_tensor = torch.tensor(normalize_xy_input_nn_model.tolist()).float()\n",
    "        # print(normalize_xy_input_nn_model_tensor)\n",
    "        prediction_for_Y_pos_increment = NN_model(normalize_xy_input_nn_model)\n",
    "        print(prediction_for_Y_pos_increment)\n",
    "        #TODO: Get the current Y (angular) position/angle of the robot. you can use the api.getPos function of fable\n",
    "        robot_current_Y_pos = api.getPos(1,moduleID)\n",
    "        #Next Y angular position of the robot will be robot_Y_pos + prediction_for_Y_pos_increment\n",
    "        robot_next_Y_pos = robot_current_Y_pos + prediction_for_Y_pos_increment\n",
    "        # print(robot_next_Y_pos)\n",
    "        #TODO: Set the next position of the robot to (-90,robot_next_Y_pos) using the setPos function of the fable.\n",
    "        api.setPos(-90,robot_next_Y_pos,moduleID)\n",
    "        api.sleep(1.5)\n",
    "        number_of_iterations_for_convergence = number_of_iterations_for_convergence + 1\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d79f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Detect the target object and obtain the coordinates of the object in the image\n",
    "cam = ct.prepare_camera()\n",
    "img = ct.capture_image(cam)\n",
    "# ct.show_camera(cam, low_green, high_green)\n",
    "x,y = ct.locate(img, low_green, high_green)\n",
    "print(x,y)\n",
    "target_x = x\n",
    "target_y = y\n",
    "print(\"target_x = \",target_x)\n",
    "print(\"target_y = \",target_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d905bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.setPos(-90,-90,moduleID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519af766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Call the control loop for a target which is detected. Record the number of iterations that the control loop spent for convergence.\n",
    "ControlLoopWithNNWithoutCMAC(target_x,target_y)\n",
    "#TODO: change your target location and try again. You may change the target 4-5 times and check how the control loop work.\n",
    "#Record the number of iterations that the control loop spent for convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdd72be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now integrate the CMAC to the previous control loop which had only the Neural Network. \n",
    "#The implementation of the CMAC can be found in code given for second week exercises.\n",
    "#TODO: Implement the control loop with both neural network and CMAC. \n",
    "def ControlLoopWithBothNNandCMAC(target_x, target_y, iter_num):\n",
    "\n",
    "    target_x_coord = target_x\n",
    "    target_y_coord = target_y\n",
    "    number_of_iterations_for_convergence = 0\n",
    "    max_iter = iter_num\n",
    "    #TODO:Intialize your best neural network model and load the saved paramemeters\n",
    "    NN_model = NN(n_feature=2,n_hidden1=100,n_hidden2=100, n_output=1)\n",
    "    NN_model.load_state_dict(torch.load('best_nn_model.pth'))\n",
    "\n",
    "    ## TODO: CMAC initialization\n",
    "    n_rfs = 20\n",
    "    beta = 10\n",
    "\n",
    "    xmin = [-1,-1]\n",
    "    xmax = [1, 1]\n",
    "\n",
    "    c = CMAC(n_rfs, xmin, xmax, beta)\n",
    "\n",
    "    ## Simulation loop\n",
    "    for i in range(max_iter):\n",
    "       \n",
    "        cam = ct.prepare_camera()\n",
    "        img = ct.capture_image(cam)\n",
    "        x,y = ct.locate(img,low_green, high_green)\n",
    "        cam_red = ct.prepare_camera()\n",
    "        img_red = ct.capture_image(cam)\n",
    "        x_red,y_red = ct.locate(img,low_red, high_red)\n",
    "        # print(x,y)\n",
    "        robot_x_coord_in_image = x\n",
    "        robot_y_coord_in_image = y\n",
    "        x_coord_error = x_red - robot_x_coord_in_image;\n",
    "        y_coord_error = y_red - robot_y_coord_in_image;\n",
    "        # print(x_coord_error,y_coord_error)\n",
    "        # x_coord_error = (x_coord_error-mean_x_pos_2)/std_x_pos_2\n",
    "        # y_coord_error = (y_coord_error-mean_y_pos_2)/std_y_pos_2\n",
    "        x_prev = x_coord_error\n",
    "        y_prev = y_coord_error\n",
    "        \n",
    "        ## TODO: Implement the CMAC controller into the loop\n",
    "        \n",
    "        x_cmac = [x_red ,robot_x_coord_in_image]\n",
    "        angle_cmac = c.predict(x_cmac)\n",
    "\n",
    "        # Iterate simulation dynamics\n",
    "        \n",
    "    \n",
    "        #Here if the errors are less than twenty pixels we assume robot reaches the target. \n",
    "        # However you can choose any reasonable threshold value instead of 20.\n",
    "        # if (np.abs(x_coord_error) < (1+x_prev*1.02) and np.abs(y_coord_error) < (1+y_coord_error*1.02)):\n",
    "        #     print(\"number of iterations for convergence = \", number_of_iterations_for_convergence)\n",
    "        #     break\n",
    "        \n",
    "        xy_input_nn_model = [x_coord_error,y_coord_error]\n",
    "        # print(xy_input_nn_model)\n",
    "        xy_input_nn_model = np.array(xy_input_nn_model)\n",
    "        #TODO: normalize the input to the Neural network model using meaning and variance of the training set inputs.\n",
    "        normalize_xy_input_nn_model = (torch.tensor(xy_input_nn_model) - mean_of_train_input)/std_of_the_train_input\n",
    "        # normalize_xy_input_nn_model = xy_input_nn_model\n",
    "        # print(normalize_xy_input_nn_model)\n",
    "        # normalize_xy_input_nn_model_tensor = torch.tensor(normalize_xy_input_nn_model.tolist()).float()\n",
    "        # print(normalize_xy_input_nn_model_tensor)\n",
    "        prediction_for_Y_pos_increment = NN_model(normalize_xy_input_nn_model)\n",
    "        # print(prediction_for_Y_pos_increment)\n",
    "        #TODO: Get the current Y (angular) position/angle of the robot. you can use the api.getPos function of fable\n",
    "        robot_current_Y_pos = api.getPos(1,moduleID)\n",
    "        #Next Y angular position of the robot will be robot_Y_pos + prediction_for_Y_pos_increment\n",
    "        robot_next_Y_pos = robot_current_Y_pos + prediction_for_Y_pos_increment\n",
    "        # print(robot_next_Y_pos)\n",
    "        # print(prediction_for_Y_pos_increment.detach().numpy())\n",
    "        c.learn(prediction_for_Y_pos_increment.detach().numpy())\n",
    "        print(angle_cmac)\n",
    "        robot_nn_and_cmac = robot_next_Y_pos + angle_cmac\n",
    "\n",
    "        #TODO: Set the next position of the robot to (-90,robot_next_Y_pos) using the setPos function of the fable.\n",
    "        api.setPos(-90,robot_nn_and_cmac,moduleID)\n",
    "        api.sleep(1.5)\n",
    "        number_of_iterations_for_convergence = number_of_iterations_for_convergence + 1\n",
    "        \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcc2fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ControlLoopWithBothNNandCMAC(target_x,target_y, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f6aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Compare the number of iteration it takes for convergence in the control loop with \n",
    "# neural network only and with both CMAC and neural network."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97b1ca7657afa4cca8b89ccd445cd43dbad4b1535d3709ba624a8852d37759e0"
  },
  "kernelspec": {
   "display_name": "Python [conda env:biocontrol] *",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
