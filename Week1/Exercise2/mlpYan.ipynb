{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 Exercise 1.2- Group 2\n",
    "**s232161-Xiaoyu Yan 25%**\\\n",
    "**s Marcel Zelent 25%**\\\n",
    "**s Linna Li 25%**\\\n",
    "**s Nicolaus 25%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from activation import ActivationFunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \"\"\" \n",
    "      Perceptron neuron model\n",
    "      Parameters\n",
    "      ----------\n",
    "      n_inputs : int\n",
    "         Number of inputs\n",
    "      act_f : Subclass of `ActivationFunction`\n",
    "         Activation function\n",
    "    \"\"\"\n",
    "    def __init__(self, n_inputs, act_f):\n",
    "        \"\"\"\n",
    "         Perceptron class initialization\n",
    "         TODO: Write the code to initialize weights and save the given activation function\n",
    "        \"\"\"\n",
    "        if not isinstance(act_f, type) or not issubclass(act_f, ActivationFunction):\n",
    "            raise TypeError('act_f has to be a subclass of ActivationFunction (not a class instance).')\n",
    "        # weights\n",
    "        np.random.seed(42)\n",
    "        self.w = np.random.normal(0, 1, (n_inputs))#np.random.normal(mean, standard deviation, size)\n",
    "        # activation function\n",
    "        self.f = act_f()\n",
    "        self.bias = np.random.normal(0, 1, (1))\n",
    "\n",
    "        if self.f is not None and not isinstance(self.f, ActivationFunction):\n",
    "            raise TypeError(\"self.f should be a class instance.\")\n",
    "\n",
    "    def activation(self, x):\n",
    "        \"\"\"\n",
    "         It computes the activation `a` given an input `x`\n",
    "         TODO: Fill in the function to provide the correct output\n",
    "         NB: Remember the bias\n",
    "        \"\"\"\n",
    "        a = np.dot(self.w.T, x) + self.bias\n",
    "        return a\n",
    "\n",
    "    def output(self, a):\n",
    "        \"\"\"\n",
    "         It computes the neuron output `y`, given the activation `a`\n",
    "         TODO: Fill in the function to provide the correct output\n",
    "        \"\"\"\n",
    "        y = self.f.forward(a)\n",
    "        return y\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "         It computes the neuron output `y`, given the input `x`\n",
    "         TODO: Fill in the function to provide the correct output\n",
    "        \"\"\"\n",
    "        a = self.activation(x)\n",
    "        y_out = self.output(a)\n",
    "        return y_out\n",
    "\n",
    "    def gradient(self, a):\n",
    "        \"\"\"\n",
    "         It computes the gradient of the activation function, given the activation `a`\n",
    "        \"\"\"\n",
    "        return self.f.gradient(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(ActivationFunction):\n",
    "    \"\"\" \n",
    "      Sigmoid activation: `f(x) = 1/(1+e^(-x))`\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "         Activation function output.\n",
    "         TODO: Change the function to return the correct value, given input `x`.\n",
    "        \"\"\"\n",
    "        return 1/(1+np.exp(-x))\n",
    "\n",
    "    def gradient(self, x):\n",
    "        \"\"\"\n",
    "         Activation function derivative.\n",
    "         TODO: Change the function to return the correct value, given input `x`.\n",
    "        \"\"\"\n",
    "        return self.forward(x) * (1 - self.forward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearActivation(ActivationFunction):\n",
    "    \"\"\" \n",
    "      Linear activation: `f(x) = x`\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "         Activation function output.\n",
    "         TODO: Change the function to return the correct value, given input `x`.\n",
    "        \"\"\"\n",
    "        return x\n",
    "\n",
    "    def gradient(self, x):\n",
    "        \"\"\"\n",
    "         Activation function derivative.\n",
    "         TODO: Change the function to return the correct value, given input `x`.\n",
    "        \"\"\"\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, num_inputs, num_units, act_f):\n",
    "        \"\"\" \n",
    "         Initialize the layer, creating `num_units` perceptrons with `num_inputs` each. \n",
    "        \"\"\"\n",
    "        # TODO Create the perceptrons required for the layer\n",
    "        self.num_units = num_units\n",
    "        self.ps = []\n",
    "        for i in range(num_units):\n",
    "            self.ps.append(Perceptron(num_inputs, act_f))\n",
    "\n",
    "    def activation(self, x):\n",
    "        \"\"\" Returns the activation `a` of all perceptrons in the layer, given the input vector`x`. \"\"\"\n",
    "        return np.array([p.activation(x) for p in self.ps])\n",
    "\n",
    "    def output(self, a):\n",
    "        \"\"\" Returns the output `o` of all perceptrons in the layer, given the activation vector `a`. \"\"\"\n",
    "        return np.array([p.output(ai) for p, ai in zip(self.ps, a)])\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\" Returns the output `o` of all perceptrons in the layer, given the input vector `x`. \"\"\"\n",
    "        return np.array([p.predict(x) for p in self.ps])\n",
    "\n",
    "    def gradient(self, a):\n",
    "        \"\"\" Returns the gradient of the activation function for all perceptrons in the layer, given the activation vector `a`. \"\"\"\n",
    "        return np.array([p.gradient(ai) for p, ai in zip(self.ps, a)])\n",
    "\n",
    "    def update_weights(self, dw):\n",
    "       \"\"\" \n",
    "       Update the weights of all of the perceptrons in the layer, given the weight change of each.\n",
    "       Input size: (n_inputs+1, n_units)\n",
    "       \"\"\"\n",
    "       for i in range(self.num_units):\n",
    "          self.ps[i].w += dw[:,i]\n",
    "\n",
    "    @property\n",
    "    def w(self):\n",
    "        \"\"\"\n",
    "         Returns the weights of the neurons in the layer.\n",
    "         Size: (n_inputs+1, n_units)\n",
    "        \"\"\"\n",
    "        return np.array([p.w for p in self.ps]).T\n",
    "\n",
    "    def import_weights(self, w):\n",
    "        \"\"\" \n",
    "         Import the weights of all of the perceptrons in the layer.\n",
    "         Input size: (n_inputs+1, n_units)\n",
    "        \"\"\"\n",
    "        for i in range(self.num_units):\n",
    "           self.ps[i].w = w[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.88794279]\n",
      " [0.88794279]\n",
      " [0.88794279]\n",
      " [0.88794279]\n",
      " [0.88794279]]\n",
      "[[ 0.49671415  0.49671415  0.49671415  0.49671415  0.49671415]\n",
      " [-0.1382643  -0.1382643  -0.1382643  -0.1382643  -0.1382643 ]]\n"
     ]
    }
   ],
   "source": [
    "layer = Layer(2, 5, Sigmoid)\n",
    "pre = layer.predict([np.pi, 1])\n",
    "print(pre)\n",
    "print(layer.w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2-3\n",
    "5 inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    \"\"\" \n",
    "      Multi-layer perceptron class\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_inputs : int\n",
    "       Number of inputs\n",
    "    n_hidden_units : int\n",
    "       Number of units in the hidden layer\n",
    "    n_outputs : int\n",
    "       Number of outputs\n",
    "    alpha : float\n",
    "       Learning rate used for gradient descent\n",
    "    \"\"\"\n",
    "    def __init__(self, num_inputs, n_hidden_units, n_outputs, alpha=0.01):\n",
    "       self.num_inputs = num_inputs\n",
    "       self.n_hidden_units = n_hidden_units\n",
    "       self.n_outputs = n_outputs\n",
    "\n",
    "       self.alpha = alpha\n",
    "\n",
    "       # TODO: Define a hidden layer and the output layer\n",
    "       self.l1 = Layer(self.num_inputs, self.n_hidden_units, Sigmoid)# hidden layer 1\n",
    "       self.l_out = Layer(self.n_hidden_units, self.n_outputs, LinearActivation) # output layer\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\" \n",
    "        Forward pass prediction given the input x\n",
    "        TODO: Write the function\n",
    "        \"\"\"\n",
    "        out1 = self.l1.predict(x)\n",
    "        out2 = self.l_out.predict(out1)\n",
    "        return out2\n",
    "\n",
    "    def train(self, inputs, outputs):\n",
    "        \"\"\"\n",
    "          Train the network \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        `x` : numpy array\n",
    "           Inputs (size: n_examples, n_inputs)\n",
    "        `t` : numpy array\n",
    "           Targets (size: n_examples, n_outputs)\n",
    "\n",
    "        TODO: Write the function to iterate through training examples and apply gradient descent to update the neuron weights\n",
    "        \"\"\"\n",
    "        # Loop over training examples\n",
    "        dw1 = np.zeros_like(self.l1.w)\n",
    "        dw_out = np.zeros_like(self.l_out.w)\n",
    "        \n",
    "        for x,t in zip(inputs, outputs):\n",
    "            # Forward pass\n",
    "\n",
    "            a1 = self.l1.activation(x)\n",
    "            o1 = self.l1.output(a1)\n",
    "            a_out = self.l_out.activation(o1)\n",
    "            o_out = self.l_out.output(a_out)\n",
    "\n",
    "            # Backpropagation\n",
    "            delta_out = (o_out - t) * self.l_out.gradient(a_out)\n",
    "            delta1 = self.l1.gradient(a1) * self.l_out.w[1:].dot(delta_out)\n",
    "\n",
    "            # Add weight change contributions to temporary array\n",
    "            o0 = np.insert(x, 0, 1)  # Add bias term\n",
    "            o1 = np.insert(o1, 0, 1)  # Add bias term\n",
    "\n",
    "            dw1 += delta1.reshape(-1, 1).dot(o0.reshape(1, -1)).T\n",
    "            dw_out += np.outer(o1, delta_out)\n",
    "\n",
    "               # Update weights\n",
    "        self.l1.update_weights(-self.alpha * dw1)\n",
    "        self.l_out.update_weights(-self.alpha * dw_out)\n",
    "\n",
    "        # Forward pass\n",
    "\n",
    "\n",
    "        # Backpropagation\n",
    "\n",
    "\n",
    "        # Add weight change contributions to temporary array\n",
    "         \n",
    "        # Update weights\n",
    "      \n",
    "        return None # remove this line\n",
    "\n",
    "    def export_weights(self):\n",
    "        return [self.l1.w, self.l2.w]\n",
    "   \n",
    "    def import_weights(self, ws):\n",
    "        if ws[0].shape == (self.l1.n_units, self.n_inputs+1) and ws[1].shape == (self.l2.n_units, self.l1.n_units+1):\n",
    "            print(\"Importing weights..\")\n",
    "            self.l1.import_weights(ws[0])\n",
    "            self.l2.import_weights(ws[1])\n",
    "        else:\n",
    "            print(\"Sizes do not match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.49671415  0.49671415  0.49671415]\n",
      " [-0.1382643  -0.1382643  -0.1382643 ]]\n",
      "[[ 0.49671415]\n",
      " [-0.1382643 ]\n",
      " [ 0.64768854]]\n"
     ]
    }
   ],
   "source": [
    "xdata = [np.pi, 1]\n",
    "mlp = MLP(2, 3, 1)\n",
    "mlp.predict(xdata)\n",
    "print(mlp.l1.w)\n",
    "print(mlp.l_out.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prediction_error(model, x, t):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    x: xdata input\n",
    "    t: ground truth\n",
    "    \"\"\"\n",
    "    y = []\n",
    "    for i in range(x.shape[0]):\n",
    "        y.append(model.predict(x[i, :]))\n",
    "    y = np.array(y).T[0]\n",
    "    n = t.shape[0]\n",
    "    error = np.sum((y - t)**2) / n\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.257035366351461\n"
     ]
    }
   ],
   "source": [
    "data = np.array( [ [0.5, 0.5, 0], [1.0, 0, 0], [2.0, 3.0, 0], [0, 1.0, 1], [0, 2.0, 1], [1.0, 2.2, 1] ] )\n",
    "xdata = data[:,:2]\n",
    "ydata = data[:,2]\n",
    "error = calc_prediction_error(mlp, xdata, ydata)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.213701451707424\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 0]])\n",
    "xdata = data[:, :2]\n",
    "ydata = data[:, 2]\n",
    "error = calc_prediction_error(mlp, xdata, ydata)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,2) (3,2) (2,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m error \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mxor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mydata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     error\u001b[38;5;241m.\u001b[39mappend(calc_prediction_error(xor, xdata, ydata))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n",
      "Cell \u001b[1;32mIn[7], line 69\u001b[0m, in \u001b[0;36mMLP.train\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m     66\u001b[0m o0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minsert(x, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Add bias term\u001b[39;00m\n\u001b[0;32m     67\u001b[0m o1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minsert(o1, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Add bias term\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m \u001b[43mdw1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdelta1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\n\u001b[0;32m     70\u001b[0m dw_out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(o1, delta_out)\n\u001b[0;32m     72\u001b[0m    \u001b[38;5;66;03m# Update weights\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,2) (3,2) (2,2) "
     ]
    }
   ],
   "source": [
    "xor = MLP(2, 2, 1)\n",
    "error = []\n",
    "for epoch in range(1000):\n",
    "    xor.train(xdata, ydata)\n",
    "    error.append(calc_prediction_error(xor, xdata, ydata))\n",
    "for i in range(4):\n",
    "    print(xor.predict(xdata[i, :]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the error\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(error)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 0.16847205839448753\n",
      "Epoch 1000, Cost: 0.12342387673300459\n",
      "Epoch 2000, Cost: 0.12017696859185573\n",
      "Epoch 3000, Cost: 0.10520928718396298\n",
      "Epoch 4000, Cost: 0.06439215299274101\n",
      "Epoch 5000, Cost: 0.006669983757727551\n",
      "Epoch 6000, Cost: 6.435997125958374e-05\n",
      "Epoch 7000, Cost: 3.675318010755684e-07\n",
      "Epoch 8000, Cost: 2.0057516512346507e-09\n",
      "Epoch 9000, Cost: 1.0909082608361319e-11\n",
      "Output: [[2.27181253e-07 9.99999675e-01 9.99999674e-01 4.58777048e-07]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def linear_activation(x):\n",
    "    return x\n",
    "\n",
    "def initialize_parameters(input_size, hidden_size, output_size):\n",
    "    np.random.seed(42)\n",
    "    weights_hidden = np.random.rand(hidden_size, input_size)\n",
    "    biases_hidden = np.zeros((hidden_size, 1))\n",
    "\n",
    "    weights_output = np.random.rand(output_size, hidden_size)\n",
    "    biases_output = np.zeros((output_size, 1))\n",
    "\n",
    "    parameters = {\n",
    "        'weights_hidden': weights_hidden,\n",
    "        'biases_hidden': biases_hidden,\n",
    "        'weights_output': weights_output,\n",
    "        'biases_output': biases_output\n",
    "    }\n",
    "\n",
    "    return parameters\n",
    "\n",
    "def forward_propagation(inputs, parameters):\n",
    "    # Hidden layer\n",
    "    hidden_activation = sigmoid(np.dot(parameters['weights_hidden'], inputs) + parameters['biases_hidden'])\n",
    "\n",
    "    # Output layer\n",
    "    output_activation = linear_activation(np.dot(parameters['weights_output'], hidden_activation) + parameters['biases_output'])\n",
    "\n",
    "    cache = {\n",
    "        'hidden_activation': hidden_activation,\n",
    "        'output_activation': output_activation\n",
    "    }\n",
    "\n",
    "    return output_activation, cache\n",
    "\n",
    "def backward_propagation(inputs, outputs, cache, parameters, learning_rate):\n",
    "    m = inputs.shape[1]\n",
    "\n",
    "    # Output layer\n",
    "    output_error = outputs - cache['output_activation']\n",
    "    output_delta = output_error  # Linear activation function derivative is 1\n",
    "\n",
    "    # Hidden layer\n",
    "    hidden_error = np.dot(parameters['weights_output'].T, output_delta)\n",
    "    hidden_delta = cache['hidden_activation'] * (1 - cache['hidden_activation']) * hidden_error\n",
    "\n",
    "    # Update parameters\n",
    "    parameters['weights_output'] += learning_rate * np.dot(output_delta, cache['hidden_activation'].T) / m\n",
    "    parameters['biases_output'] += learning_rate * np.sum(output_delta, axis=1, keepdims=True) / m\n",
    "\n",
    "    parameters['weights_hidden'] += learning_rate * np.dot(hidden_delta, inputs.T) / m\n",
    "    parameters['biases_hidden'] += learning_rate * np.sum(hidden_delta, axis=1, keepdims=True) / m\n",
    "\n",
    "    return parameters\n",
    "\n",
    "def train_neural_network(inputs, outputs, hidden_size, learning_rate, epochs):\n",
    "    input_size = inputs.shape[0]\n",
    "    output_size = outputs.shape[0]\n",
    "\n",
    "    parameters = initialize_parameters(input_size, hidden_size, output_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        output_activation, cache = forward_propagation(inputs, parameters)\n",
    "        parameters = backward_propagation(inputs, outputs, cache, parameters, learning_rate)\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            cost = np.mean(np.square(outputs - output_activation)) / 2\n",
    "            print(f'Epoch {epoch}, Cost: {cost}')\n",
    "\n",
    "    return parameters\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'inputs' and 'outputs' are your input and output data, with each column representing a data point\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]).T\n",
    "outputs = np.array([[0, 1, 1, 0]])\n",
    "\n",
    "hidden_size = 2\n",
    "learning_rate = 0.1\n",
    "epochs = 10000\n",
    "\n",
    "trained_parameters = train_neural_network(inputs, outputs, hidden_size, learning_rate, epochs)\n",
    "\n",
    "# Test the trained neural network\n",
    "output_activation, _ = forward_propagation(inputs, trained_parameters)\n",
    "print(f'Output: {output_activation}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
